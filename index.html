<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shuai Zhang Assistant Professor@NJIT </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Shuai@NJIT</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="cv\CV.pdf">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="research.html">Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
  <div class="menu-category">Teaching</div>
<div class="menu-item"><a href="Teaching.html">DS675 (Fall 2023)</a></div>
<div class="menu-category">Others</div>
<div class="menu-item"><a href="talk.html">Talks</a></div>
</td>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shuai Zhang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="cv/bio.jpeg" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td>
<td align="left"><p>Assistant Professor <br />
  Department of Data Science <br />
  New Jersey Institute of Technology <br />
E-mail: <a href="mailto:sz457@njit.edu">sz457 at njit.edu </a> <br />
  <a href="https://scholar.google.com/citations?user=RvDk-iwAAAAJ&hl=en">Google Scholar</a>
  &nbsp; &nbsp; 
  <a href="cv/CV.pdf"> CV 
  </a> 
  </p>
</td></tr></table>
<h2>About me</h2>
<p>Shuai Zhang joined NJIT from Rensselaer Polytechnic Institute (RPI), where he was a postdoctoral researcher focused on theoretical and algorithmic foundations of deep learning. His interests span deep learning, optimization, data science and signal processing, with an emphasis on learning theory – the design of machine learning algorithms – and the development of efficient and trustworthy AI. Challenges to effective AI implementation remain, however, such as the high cost of computation, the limited availability of high-quality labeled data, generalizability across domains, and the lack of transparency – the absence of explanations for how AI works, raising safety concerns in areas such as healthcare and autonomous control systems. Zhang develops theoretical explanations of how AI works. He also creates learning algorithms to reduce AI model complexity and the required number of training samples, improving the reliability and efficiency of AI systems in applications such as cyber-physical systems, computer vision, and spatial-temporal data analysis. Zhang has collaborated with the IBM Thomas J. Watson Research Center and the MIT-IBM Watson AI Lab on scalable and trustworthy AI projects. His research has been published in machine learning conferences and journals, including ICML, NeurIPS, ICLR, and IEEE TNNLS. He received his Ph.D. from the Department of Electrical, Computer, and Systems Engineering (ECSE) at Rensselaer Polytechnic Institute (RPI) in 2021, supervised by Prof. <a href="https://sites.ecse.rpi.edu/~wang/">Meng Wang</a>. He received his Bachelor's degree in Electrical Engineering (EE) at the University of Science and Technology of China (USTC) in 2016. </p><div class="infoblock">
<div class="blocktitle"></div>
<div class="blockcontent">
<p>I am joining the Department of Data Science at New Jersey Institute of Technology (NJIT) as an Assistant Professor in Fall 2023. I am looking for self-motivated students with interests in data science, machine/deep learning, and signal processing. </p>
</div>
</div>
<h2>Research</h2>
<p> My long-term research objective is to study the theoretical foundations of artificial
intelligence and design more principled and efficient algorithms for better, safer, and
more efficient AI applications. As part of my research, my interests covering the following areas: </p>
<ul>
<li><p>Machine/Deep Learning</p>
</li>
<li><p>Learning Theory</p>
</li>
<li><p>High-dimensional Data Analysis</p>
</li>
<li><p>Spatio-temporal Data Analysis</p>
</li>
<li><p>Deep Reinforcement Learning</p>
</li>
<li><p>Probability and Statistical Inference</p>
</li>
</ul>  
<h2>Recent news</h2>
<ul>
<li><p>Apr. 2023: One paper has been accepted at ICML 2023. </p></li>
<li><p>Mar. 2023: Invited talk for the AI Cluster Seminar at University at Albany. </p>
</li>
<li><p>Mar. 2023: Invited talk for the Computer Science Seminar at UMass Lowell. </p>
</li>
<li><p>Mar. 2023: Invited talk for the Computer Science Seminar at Oklahoma State University. </p>
</li>
<li><p>Feb. 2023: Invited talk for the Computer Science Seminar at University of Memphis. </p>
</li>
<li><p>Jan. 2023: Our paper on  <a href="https://openreview.net/forum?id=4UldFtZ_CVF">Joint Sparse Learning for Graph Neural Networks</a>  is accepted to the International Conference on Learning Representations (ICLR) 2023! </p>
</li>
<li><p>Jan. 2023: Invited talk for the Computer Science Colloquium at New Mexico State University. </p>
</li>
<li><p>Nov. 2022: Invited talk for the Electrical, and Computer Engineering Seminar at Iowa State University. </p>
</li>
<li><p>Mar. 2022: Paper with Hongkang "Learning and generalization of one-hidden-layer neural networks, going beyond standard Gaussian data" is accepted to 56th Annual Conference on Information Sciences and Systems (CISS), 2022. </p>
</li>
<li><p>Jan. 2022: Our paper "<a href="https://openreview.net/forum?id=qiMXBIf4NfB">How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis</a>" is accepted to the 10th International Conference on Learning Representations (ICLR) 2022!   </p>
</li>  

<li><p>Dec. 2021:  Shuai successfully defended his thesis. Thanks to Drs. <a href="https://sites.ecse.rpi.edu/~wang/">Meng Wang</a>, <a href=" https://www.isg-rpi.com/">Ali Tajer </a>, <a href=" https://homepages.rpi.edu/~mitchj/"> John E. Mitchell </a>, and <a href=" https://sites.ecse.rpi.edu/~yazici/"> 	Birsen Yazıcı </a> for serving as the commitee members. </p>
</li>  

<li><p> Sep. 2021: Our paper "<a href="https://papers.nips.cc/paper/2021/file/15f99f2165aa8c86c9dface16fefd281-Paper.pdf">Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks</a>" is accepted to the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS) 2021!   </p>
</li>  
<li><p>May 2021: Shuai won the Allen B. DuMont Prize from the Department of ECSE at RPI (The award is presented to outstanding doctoral graduates, and two students for the Department of ECSE at 2021). </p>
</li>

<li><p>Jun. 2020: Our paper "Improved Linear Convergence of Training CNNs with Generalizability Guarantees: A One-hidden-layer Case" is accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS). </p>
</li>

<li><p>Jun. 2020: Our paper "<a href="https://proceedings.mlr.press/v119/zhang20y">Fast Learning of Graph Neural Networks with Guaranteed Generalizability: One-hidden-layer Case</a>" is accepted to International Conference on Machine Learning (ICML) 2020. </p>
</li>

<li><p>Sep. 2019: Shuai received Rensselaer's Founders Award of Excellence. </p>
</li>

<li><p>Feb. 2019: Our paper "Correction of Corrupted Columns in Robust Matrix Completion by Exploiting the Hankel Structure" is accepted to IEEE Transactions on Signal Processing (TSP). </p>
</li>

<li><p>Mar. 2018: Our paper "Correction of Simultaneous Bad Measurements by Exploiting the Low-rank Hankel Structure" is accepted to IEEE International Symposium on Information Theory (ISIT) 2018. </p>
</li>

<li><p>Mar. 2018: Paper with Yingshuai "Multi-Channel Hankel Matrix Completion through Nonconvex Optimization" is accepted to IEEE Journal of Selected Topics in Signal Processing (JSTSP)!  </p>
</li>

<li><p>Sep. 2017:  Paper with Yingshuai "Multi-Channel Missing Data Recovery by Exploiting the Low-rank Hankel Structures" is accepted to IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP) 2017.  </p>
</li>

</ul>  
</div>
</td>
</tr>
</table>
</body>
</html>
